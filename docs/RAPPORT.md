# Rapport Machine Learning

## Introduction
Ce rapport a pour but de d√©crire les √©tapes et les √©tudes r√©alis√©es √† l'√©laboration des mod√®les de Machine Learning de classification et de r√©gression, en passant par l'exploration des donn√©es, la validation des variables d'entra√Ænement, leur traitement, puis les strat√©gies mises en place pour s√©lectionner des mod√®les, et enfin, leur √©valuation.
### üéØStrat√©gie
>Afin d'orienter l'exploration des donn√©es, nous listons le cahier des charges que nous souhaitons impl√©menter au sein de l'application.

**Ergonomie d'utilisation:** 
- L'utilisateur doit utiliser les mod√®les pour pouvoir pr√©dire la **classe DPE** de son appartement et/ou **sa consommation**. Ainsi, l'utilisateur doit pouvoir utiliser sa consommation r√©elle si elle est connue afin d'am√©liorer la pr√©diction de sa classe.
-  L'utilisateur de notre application ne pourra fournir qu'une quantit√© limit√© de donn√©es pour la pr√©diction de sa classe. Ainsi les donn√©es trop techniques, ou difficilement obtenable seront √©vit√©es afin de fournir un formulaire de pr√©diction coh√©rent.
 
 **Pr√©dictions:** 
 - Nous souhaitons √©laborer un mod√®le capable de pr√©dire chacune des **7 classes DPE**.
- Concernant la r√©gression, nous pr√©dirons le **co√ªt total 5 usages**.
>[!Remarque]
>Le co√ªt total 5 usages fait partie de l'enjeu de pr√©diction de la r√©gression et fait partie des donn√©es utiles √† l'estimation de la classe DPE. Un utilisateur poss√©dant sa consommation pourra directement s'en servir pour pr√©dire sa classe DPE. Dans le cas o√π l'utilisateur ne la poss√®de pas, le **mod√®le de regression pr√©dira la consommation th√©orique**, et cet √©l√©ment sera ensuite utilis√© pour **une double pr√©diction pour pr√©dire la classe DPE**.

**Scope:**
- Nous souhaitons pouvoir √©laborer un mod√®le utilisable sur la l'ensemble du **territoire Fran√ßais**.
---
## Donn√©es

### Sources
 **API de l'ademe**
 Source principale des donn√©es de l'entra√Ænement des mod√®les de classification et de r√©gression.
- DPE logements existants: https://data.ademe.fr/datasets/dpe03existant
- DPE logements neufs: https://data.ademe.fr/datasets/dpe02neuf

**Dataset Communes de France**
Dataset permettant de r√©cup√©rer l'altitude des communes de France.
- https://www.data.gouv.fr/datasets/communes-france-1/

**API Open-Elevation**
API permettant de r√©cup√©rer l'altitude √† l'aide de la longitude et la latitude, permettant de compl√©ter les donn√©es parfois manquantes du *Dataset communes de France*.
- https://open-elevation.com/

**Tableau de r√©partition des zones climatiques en France**
Permettant de faire intervenir les diff√©rences de climat dans la pr√©diction.
- https://www.ecologie.gouv.fr/sites/default/files/documents/La%20r%C3%A9partition%20des%20d%C3%A9partements%20par%20zone%20climatique.pdf

### Extraction des donn√©es
La majorit√© de la donn√©e a √©t√© r√©cup√©r√©e de l'API de **l'ademe**. Afin d'√©tablir un data set repr√©sentatif de la totalit√© de la France, nous avons extrait tout d'abord extrait la *liste de tous les d√©partements et le nombre d'√©l√©ments* en utilisant les routes d'API d'agr√©gation. Cette liste de d√©partement nous a ensuite permis d'extraire 10.000 lignes de chaque d√©partement, √† la fois sur les *logements existants* et sur *les logements neufs*. Ainsi, environ 1 millions de lignes ont pu √™tre r√©cup√©r√©es sur l'ensemble du territoire, comptabilisant plus de 2 heures de t√©l√©chargement.
### S√©lection des variables
Les variables utilis√©es pour nourrir les mod√®les de pr√©diction ont √©t√© tri√©es:
- En √©tudiant la **documentation de l'√©tablissement d'un DPE** et en s√©lectionnant toutes les variables qui semblent pertinentes et li√©es √† la consommation d'√©nergie.
- Parmi de nombreuses variables, celles qui poss√©daient **des valeurs nulles √† hauteur de plus de 10% du dataset** ont √©t√© **retir√©es**.
- Les variables dont l'information peut √™tre facilement retrouv√©es ont √©t√© privil√©gi√©s: ces variables appara√Ætront pour la plupart dans le formulaire de pr√©diction de l'utilisateur, il ne faut donc pas de demande trop *techniques*.
- Les variables de co√ªts ou de consommation (pour le mod√®le de classification), toutes tr√®s corr√©l√©es entre elles, ont √©t√© limit√©es au `co√ªt_total_5_usages` de l'ann√©e en cours.
- Des variables suppl√©mentaires ont √©t√© ajout√©s de sources externes: **l'altitude et la zone climatique**, pouvant toutes deux influer sur la consommation d'√©nergie.

Ainsi, la liste suivante de variables ont √©t√© retenus:

| Nom de la variable                      | Description                                            | Unit√©                                                              | Interpr√©tation                                                                       |
| --------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------ |
| **`cout_total_5_usages`**               | Co√ªt total annuel associ√© aux 5 usages √©nerg√©tiques    | ‚Ç¨ / an                                                             | Refl√®te la d√©pense √©nerg√©tique globale du logement.                                  |
| **`surface_habitable_logement`**        | Surface habitable totale du logement                   | m¬≤                                                                 | Plus la surface est grande, plus la consommation √©nerg√©tique potentielle est √©lev√©e. |
| **`nombre_niveau_logement`**            | Nombre total de niveaux (√©tages) du logement           | nombre entier                                                      | Influence la r√©partition thermique et la surface d‚Äô√©change avec l‚Äôext√©rieur.         |
| **`age_batiment`**                      | √Çge du b√¢timent depuis sa construction                 | ann√©es                                                             | Les b√¢timents anciens ont souvent une isolation moins performante.                   |
| **`altitude_moyenne`**                  | Altitude moyenne du logement                           | m√®tres                                                             | Influence les conditions climatiques locales (temp√©rature moyenne, humidit√©).        |
| **`type_energie_principale_chauffage`** | Source d‚Äô√©nergie principale utilis√©e pour le chauffage | √©lectricit√©, gaz, fioul, bois, pompe √† chaleur...                  | Influence directe sur le co√ªt √©nerg√©tique et les √©missions.                          |
| **`type_batiment`**                     | Cat√©gorie du b√¢timent r√©sidentiel                      | maison individuelle, immeuble collectif, logement interm√©diaire... | Refl√®te les besoins √©nerg√©tiques moyens.                                             |
| **`zone_climatique`**                   | Zone climatique de localisation du logement            | H1, H2, H3                                                         | Impacte la rigueur climatique.                                                       |

### Transformation des donn√©es
Les donn√©es ont √©t√© scrupuleusement v√©rifi√©es, homog√©n√©is√©s et transform√©es pour r√©duire le bruit. La grande quantit√© de donn√©es que nous avons extraites a permis d'√©liminer certains outliers ainsi que certaines valeurs manquantes quand aucune solution raisonnable n'a pu √™tre trouv√©. Ci-dessous, le d√©tail des principales transformations effectu√©es:
- **age du b√¢timent**: Calcul√© √† partir de l'ann√©e du b√¢timent. Transform√© en √¢ge pour permettre au mod√®le d'apprendre plus facilement qu'avec l'ann√©e.
- **Co√ªt 5 usages**: Utilisation de la m√©thode *inter-quartile* pour supprimer les valeurs qui semblaient aberrates.
- **Type Energie chauffage**: Variable √† 14 modalit√©s, dont 2 principales. Les modalit√©s trop rares ont √©t√© *group√©es* dans une modalit√© 'autres'.
- **Surface logement**: Utilisation de la m√©thode interquartile pour supprimer les valeurs aberrantes.
- **Nombre niveau logement**: Les √©tages ont √©t√© limit√©es √† 10 maximum.
- **Type b√¢timent**: Suppression des lignes contenant des valeurs manquantes (peu de valeurs nulles).
- **Altitude**: L'altitude a √©t√© r√©cup√©r√©e en croisant les donn√©es r√©cup√©r√©es sur l'API √©l√©vation et le dataset des villes de France sur le code INSEE. Les donn√©es manquantes ont √©t√© moyenn√©es sur le d√©partement. 

### R√©partition des classes DPE
La r√©partition des classes DPEs apr√®s extraction est rest√©e quasiment inchang√©e lors du traitement:
<img width="553" height="425" alt="image" src="https://github.com/user-attachments/assets/44ad48dc-b23f-4783-9514-91de2423dd9c" />

---
## Mod√®le de classification
### S√©lection des mod√®les
Le choix du mod√®le a √©t√© r√©alis√© en testant et comparant plusieurs mod√®les mettant en jeux des algorithmes diff√©rents afin de chercher le plus adapt√©.
- **Des arbres**: Random Forest, XGBoost (avec et sans p√©nalisation).
- **Un classifieur lin√©aire**: R√©gression logistique.
- **Un classifieur √† fronti√®re quadratique**: Analyse discriminante quadratique.
- **Un classifieur bas√© sur le calcul des distances**: le KNN (K Nearest Neighbors).
### Pr√©paration des donn√©es entra√Ænement/test
**Pr√©paration du set d'entra√Ænement**: Utilisation d'un split **stratifi√©** 70/30.
**Pipeline de pr√©traitement**: un `Scaler` ainsi qu'un `OneHotEncoder` pour centrer r√©duire les variables d'apprentissage (sauf pour le *RandomForest*).
**Label Encoder**: Pour lab√©liser en variable num√©rique la classe DPE, permettant d'introduire la notion de hi√©rarchie entre les classes.

### D√©termination des hyperparam√®tres pour chacun des mod√®les.
La m√©thodologie suivante √† √©t√© appliqu√©e, en utilisant le m√™me set d'entra√Ænement pour tous les algorithmes :
- Recherche des meilleurs hyper-param√®tres pour chacun des algorithmes √† l'aide d'un **GridSearchCV** et un param√©trage de **5 folds** pour la **validation crois√©e stratifi√©e**. (150 entra√Ænements/mod√®les environ)
- Suivi des exp√©riences √† l'aide de la librairie **MLFlow**.
- La **m√©trique** utilis√©e pour comparer les mod√®les est la **balanced_accuracy**, permettant d'√©valuer les mod√®les en prenant en compte **les modalit√©s rares** afin d'essayer de pousser le mod√®le √† na pas n√©gliger les classes G et F, moins repr√©sent√©es.

### Comparaison des algorithmes
Une fois les hyperparam√®tres trouv√©s pour chacun des algorithmes, nous avons tent√© d'√©valuer la performance des mod√®les et de les comparer. Nous donc r√©p√©ter **30** fois la proc√©dure suivante, pour chacun des algorithmes:
- Re-g√©n√©rer le split Train/Test.
- Entra√Æner le mod√®le et effectuer l'√©valuation sur les donn√©es d'entra√Ænement. (**balanced_accuracy, accuracy, f1_score, hamming_loss**)
- **30** R√©cup√©rations des m√©triques de test: meilleure √©valuation en prenant la moyenne.
- Estimation de la stabilit√© en calculant les intervalles de confiances √† l'aide d'un **test de Student** √† 95%.
  
$$CI = \left( \bar{x} - t_{\alpha/2} \cdot \frac{s}{\sqrt{n}},\; \bar{x} + t_{\alpha/2} \cdot \frac{s}{\sqrt{n}} \right)$$

>- $\bar{x}$ ‚Üí moyenne de l‚Äô√©chantillon
>- $s$ ‚Üí √©cart-type
>- $n$ ‚Üí taille de l‚Äô√©chantillon (30)
>- $t_{\alpha/2}$‚Äã ‚Üí quantile de la loi de Student pour le niveau de confiance choisi
>- $CI$ ‚Üí intervalle de confiance

<img width="778" height="466" alt="image" src="https://github.com/user-attachments/assets/eb26b4bb-78eb-4403-8a02-21de4822a6be" />



| **Mod√®le**                 | **M√©trique**      | **Moyenne (mean)** | **√âcart-type (std)** | **IC95%**      |
| -------------------------- | ----------------- | ------------------ | -------------------- | -------------- |
| üü• **XGBoost**             | Balanced Accuracy | 0.743              | 0.001                | [0.743, 0.743] |
|                            | Accuracy          | 0.797              | 0.001                | [0.797, 0.797] |
|                            | F1-score (macro)  | 0.747              | 0.001                | [0.747, 0.748] |
|                            | F1-score (micro)  | 0.797              | 0.001                | [0.797, 0.797] |
| üü® **KNN**                 | Balanced Accuracy | 0.707              | 0.001                | [0.706, 0.707] |
|                            | Hamming Loss      | 0.203              | 0.001                | [0.203, 0.203] |
|                            | Accuracy          | 0.777              | 0.001                | [0.777, 0.778] |
|                            | F1-score (macro)  | 0.714              | 0.001                | [0.713, 0.714] |
|                            | F1-score (micro)  | 0.777              | 0.001                | [0.777, 0.778] |
|                            | Hamming Loss      | 0.223              | 0.001                | [0.222, 0.223] |
| üü¶ **Logistic Regression** | Balanced Accuracy | 0.632              | 0.001                | [0.631, 0.632] |
|                            | Accuracy          | 0.713              | 0.001                | [0.713, 0.714] |
|                            | F1-score (macro)  | 0.643              | 0.001                | [0.643, 0.644] |
|                            | F1-score (micro)  | 0.713              | 0.001                | [0.713, 0.714] |
|                            | Hamming Loss      | 0.287              | 0.001                | [0.286, 0.287] |
| üü© **QDA**                 | Balanced Accuracy | 0.537              | 0.002                | [0.536, 0.538] |
|                            | Accuracy          | 0.633              | 0.001                | [0.632, 0.633] |
|                            | F1-score (macro)  | 0.546              | 0.002                | [0.545, 0.547] |
|                            | F1-score (micro)  | 0.633              | 0.001                | [0.632, 0.633] |
|                            | Hamming Loss      | 0.367              | 0.001                | [0.367, 0.368] |
| üü´ **Random Forest**       | Balanced Accuracy | 0.292              | 0.004                | [0.290, 0.294] |
|                            | Accuracy          | 0.440              | 0.001                | [0.440, 0.441] |
|                            | F1-score (macro)  | 0.257              | 0.008                | [0.254, 0.260] |
|                            | F1-score (micro)  | 0.440              | 0.001                | [0.440, 0.441] |
|                            | Hamming Loss      | 0.560              | 0.001                | [0.559, 0.560] |

### XGBoost: √©valuation finale
Les op√©rations effectu√©es ci-dessus nous permettent de conclure notre choix pour l'**XGBoost**. Afin d'estimer la v√©ritable efficacit√© de notre algorithme. Nous effectuons un dernier split des donn√©es pour un entra√Ænement et un test. Nous pouvons ainsi g√©n√©rer la **matrice de confusion** suivante qui compl√©mente les pr√©c√©dentes mesures:

<img width="798" height="621" alt="image" src="https://github.com/user-attachments/assets/e9ce3ae5-ab99-4559-b62e-afd7071b037f" />


- Nous pouvons remarquer que l'algorithme arrive √† pr√©dire raisonnablement bien une grande partie des classes. Nous pouvons aussi noter que le mod√®le √† appris de la **hi√©rarchisation des classes**: lorsque la pr√©diction est mauvaise, le mod√®le parvient tout de m√™me √† **pr√©dire une classe proche** avec une tendance √† mod√©rer ses pr√©dictions pour les classes centrales (C et D).


### Importance des variables
La librairie **XGBoost** permettant de monter le mod√®le offre le moyen de r√©cup√©rer l'importance des variables dans la determination des classes. Cette "importance" est d√©termin√© selon deux crit√®res:
- Le nombre de fois o√π la variable √† √©t√© **utilis√©e pour s√©parer un n≈ìud de l'arbre**.
- L'importance du **Gain** engendr√© par la s√©paration de la variable (r√©duction de l'enthropie ou de l'impuret√© de Gini)
<img width="1263" height="673" alt="image" src="https://github.com/user-attachments/assets/b4ed71e7-dc35-407c-a48e-5e6aecb2219f" />

Ainsi notre mod√®le se base principalement sur **l'√¢ge du b√¢timent**, **le type d'√©nergie principale pour le chauffage**, et le **type du b√¢timent**.
